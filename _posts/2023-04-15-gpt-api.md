---
title: "Dostp do GPT od OpenAI przez API"
date: 2023-04-15
categories: 
  - "poradniki"
tags: 
  - "ai"
  - "api"
  - "chatgpt"
  - "curl"
  - "deepl"
  - "futurepedia"
  - "gpt"
  - "gpt35turbo"
  - "gpt4"
  - "llm"
  - "max_tokens"
  - "openai"
  - "php"
  - "promptengineer"
  - "temperature"
  - "tlumacz"
  - "tlumaczenie"
  - "token"
  - "translate"
  - "translator"
coverImage: "openaiapi.png"
---

[ Go to english version of this post / Przejd藕 do angielskiej wersji tego wpisu](https://blog.tomaszdunia.pl/gpt-api-eng/)

_ChatGPT_ jest ostatnio na ustach wszystkich. Wychodzi nam niemal偶e nawet z lod贸wki. W sieci, telewizji i radiu cigle syszymy rozwa偶ania _czy jest to przyszo_, _ile miejsc pracy odbierze_, _jakie偶 innowacyjne jest to rozwizanie_. C贸偶, ja tutaj nie bd si nad tym zbytnio rozwodzi, a jedynie skupi si na aspektach praktycznych, bo tak samo jak i zapewne Ty, drogi Czytelniku, **mam ju偶 troch do tego gadania po pr贸偶nicy**. Powiem jedynie kr贸tko, **AI to bez dw贸ch zda przyszo**, czy tego chcemy czy nie. Mo偶e jeszcze nie w takiej formie, ale **bdzie bardzo szybko ewoluowa i si rozwija**. Jedyne co mo偶na zrobi aby bra czynny udzia w tej przyszoci to wsi na najszybszego rumaka jakiego mamy w zagrodzie, pdzi przed siebie, dogoni ten pocig i spr贸bowa do niego **wsi p贸ki jeszcze si da**. Dla mnie _GPT_ i inne modele tego typu to innowacja wsp贸czesnych czas贸w, kt贸r **ju偶 mo偶na por贸wna do przeomu jakim byy smartfony**, a to dopiero pocztek drogi. Stajemy wicej teraz przed wyzwaniem - **wsiadasz czy zostajesz w tyle?!** Ja nie mog powiedzie, 偶e jestem ju偶 w pocigu nazwanym _EKSPres dla EKSPert贸w AI_, bo mam wra偶enie, 偶e dopiero liznem temat i to przez szyb, jednak偶e siedz na rumaku i **jak chcesz to mog Ci wzi na tylne siodo, po czym razem spr贸bujemy dogoni ten pocig**. Tym dokadnie jest ten wpis. Odpuszczajc ju偶 metaforyczne pierdu pierdu - **w tym wpisie poka偶 jak komunikowa si ze sztuczn inteligencj stworzon przez _OpenAI_**, a konkretnie korzysta z modelu _GPT_, poprzez udostpnione przez nich _API_.

_OpenAI_ oraz ich produkt maj wielu przeciwnik贸w, kt贸rzy wygaszaj (wedug mnie) suszne wtpliwoci (pozdrawiam MiKlo oraz Ryka i polecam zajrze do komentarzy pod [moim tootem](https://mastodon.tomaszdunia.pl/@to3k/110187175119834883) bdcym zapowiedzi tego wpisu). Polecam takim osobom potraktowa ten wpis jako zbi贸r informacji, kt贸re pozwol pozna swojego przeciwnika, to zawsze uatwia walk 

## ChatGPT

Syszc _OpenAI_, _GPT_ czy _sztuczna inteligencja_ uderzajca wikszo odbiorc贸w pomyli _ChatGPT_. Faktycznie jest to co co przyczynio si w znacznym stopniu do popularyzacji i dyskusji o _AI_, bo tak naprawd pozwolio zademonstrowa potg tego rozwizania. _ChatGPT_ jest zupenie darmowym narzdziem (oczywicie jest plan patny, ale my tutaj nie o tym), pozwalajcym prowadzi konwersacj ze _sztuczn inteligencj_, a raczej z modelem jzykowym (_LLM_, skr贸t od _Large Language Model_, z ang. _wielki model jzykowy_), tak jakby to byo rozmawianie z koleg na _Signalu_. Jednak wszyscy musimy zrozumie, 偶e **_ChatGPT_ to nie koniec historii i nie jest to jedyna forma dostpu do modeli uczenia maszynowego**, z kt贸rych jednym jest _GPT_, tak samo _GPT_, co jest skr贸tem od _Generative Pre-trained Transformer_ (z ang. _Generatywny Wstpnie Szkolony Przeksztatnik_ - moje autorskie tumaczenie ). Chodzi tu o zaawansowany model uczenia maszynowego, kt贸ry zosta wytrenowany na du偶ych zbiorach danych tekstowych w celu generowania sp贸jnych i logicznych sekwencji tekstu w jzyku naturalnym. Dlaczego przetumaczyem to jako _przeksztatnik_? Bo najprociej mo偶na to wszystko wytumaczy tak, 偶e **_GPT_ przeksztaca komunikaty zrozumiae dla maszyny na komunikaty zrozumiae dla czowiek i odwrotnie**. Tak, wic _ChatGPT_ mo偶na traktowa jak jedynie jedn z usug bazujcych na _GPT_. Na bazie _GPT_ ju偶 powstao wiele innych projekt贸w, a codziennie powstaj kolejne, co udowadnia strona _[Futurepedia.io](https://www.futurepedia.io/)_. **Integracja modelu _GPT_ do swojego projektu jest mo偶liwa poprzez _API_** udostpnione przez _OpenAI_ i jak si okazuje nie jest to wcale trudne, co udowodni w tym wpisie.

## Jak uzyska dostp do API

Oczywicie jak w przypadku wikszoci _API_, aby uzyska do niego dostp potrzebujemy posiada klucz. Takowy mo偶na otrzyma **rejestrujc si na stronie**: [https://auth0.openai.com/u/signup/identifier](https://auth0.openai.com/u/signup/identifier). Rejestracja jest darmowa, a po niej dostajemy na start $5 do wykorzystania na nauk/zabaw. Z pozoru te $5 wydaje si mieszn iloci, ale jak zaraz zobaczysz ile kosztuje wykonanie naprawd skomplikowanych zada to zrozumiesz, 偶e **za te pi dolk贸w mo偶na naprawd przenie niejedn g贸r**!

Po zao偶eniu konta wchodzimy do panelu zarzdzania naszym kontem i dalej do zakadki _API Keys_ lub po prostu mo偶esz p贸j na skr贸ty i skorzysta z tego linku - [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys). W tym miejscu wystarczy nacisn przycisk _+Create new secret key_ i skopiowa warto klucza, kt贸ry zostanie wywietlony w oknie, kt贸re wyskoczy.

## Zbudujmy tumacza PL-ENG wykorzystujcego model GPT

Pewnie wiele razy tumaczye co przy u偶yciu _Tumacza Google_ czy chocia偶by _DeepL_, o kt贸rym pisaem w [tym wpisie](https://blog.tomaszdunia.pl/deepl-api/). Jednak **to jak z tumaczeniem radzi sobie model _GPT_ nie spos贸b por贸wna do 偶adnego z wczeniej wspomnianych narzdzi**. W momencie pisania tego wpisu bior si na powa偶nie za tumaczenie wikszoci wpis贸w tego bloga przy wsparciu wanie rozwizania od _OpenAI_. W momencie kiedy bdzie on opublikowany pewnie ju偶 wszystkie z nich bd przetumaczone, cho to troch zale偶y od finalnej daty publikacji jak ustal dla tego wpisu oraz iloci czasu jaki bd mia na sprawdzenie wygenerowanych tumacze, bo nie ma co ukrywa, 偶e jednak trzeba je przynajmniej przejrze przed publikacj.

Wr贸my jednak do tematu. Poni偶ej przedstawiam kod skryptu, kt贸ry przy u偶yciu, znanego nam z poprzednich wpis贸w ([tego](https://blog.tomaszdunia.pl/mews/) i [tego](https://blog.tomaszdunia.pl/deepl-api/)), _cURL_ skomunikuje si z _API_ _OpenAI_ i wyle podany przez u偶ytkownika fragment tekstu do tumaczenia. Podstawowy opis poszczeg贸lnych krok贸w skryptu znajduje si standardowo w treci kodu w postaci komentarzy.

```php
<?php
    // OPENAI API TOKEN
    $token = '[TU_WKLEJ_TOKEN]';
    
    // Sprawdza czy wysano polecenie i fragment do tumaczenia
    if(!empty($_POST['polecenie']) AND !empty($_POST['fragment']))
    {
        // Je偶eli tak to pobiera zmienn POST, w kt贸rej jest przechowywany
        $polecenie = $_POST['polecenie'];
        $fragment = $_POST['fragment'];
        
        // Okrela jaki maksymalny limit token贸w mo偶emy zadeklarowa
        // Okrela ilo znak贸w fragmentu (dugo)
        $prompt_size = strlen($polecenie) + strlen($fragment);
        // Dla modelu gpt-3.5-turbo limit token贸w to 4096, wic odejmujemy wy偶ej wyliczon dugo od tego limitu
        $max_tokens = 4096-$prompt_size;

        // Tablica z informacjami wysyanymi w zapytaniu cURL
        $postfields = array(
            "model" => "gpt-3.5-turbo", // Okrelenie jaki model ma zosta u偶yty
            "messages" => [
                array(
                    "role" => "system", // Okrelenie roli wiadomoci jako ta od systemu (nadajca kontekst)
                    "content" => $polecenie // Kontekst (w naszym przypadku polecenie, co ma by zrobione)
                ), 
                array(
                    "role" => "user", // Okrelenie roli wiadomoci jako ta od u偶ytkownika
                    "content" => $fragment // Fragment do tumaczenia
                )
            ],
            "temperature" => 0.5, // Parametr, kt贸ry okrela jak kreatywna (losowa) ma by odpowied藕
            "max_tokens" => $max_tokens // Okrelenie jak duga mo偶e by odpowied藕
        );
        // Konwertuje powy偶sz tablic w obiekt JSON, bo w takiej formie nale偶y go wysa
        $postfields = json_encode($postfields);

        // Nag贸wki zapytania
        $headers = array(
            "Content-Type: application/json", // Okrelenie typu wysyanej treci - JSON
            "Authorization: Bearer ".$token // Token do uwierzytelnienia przy komunikacji z API
        );
        
        // Inicjalizuje zapytanie cURL
        $curl = curl_init();
        // Okrela URL do kt贸rego ma zosta skierowane zapytanie
        curl_setopt($curl, CURLOPT_URL, "https://api.openai.com/v1/chat/completions");
        // Nakazuje cURL zwr贸ci wynik zapytania
        curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);
        // Deklaruje, 偶e ma to by zapytanie typu POST
        curl_setopt($curl, CURLOPT_POST, 1);
        // Definiuje dane do przekazania
        curl_setopt($curl, CURLOPT_POSTFIELDS, $postfields);
        // Ustawia nag贸wki
        curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
        // Wysya zapytanie i zapisuje zdekodowany wynik do zmiennej
        $result = json_decode(curl_exec($curl), true);
        // Zamyka poczenie
        curl_close ($curl);
        // Wyciga z wyniku przetumaczon tre
        $translated = $result['choices']['0']['message']['content'];
        // Wyciga z wyniku dugo zapytania (tokeny)
        $prompt_tokens = $result['usage']['prompt_tokens'];
        // Wyciga z wyniku dugo odpowiedzi (tokeny)
        $completion_tokens = $result['usage']['completion_tokens'];
        // Wyciga z wyniku cakowit ilo u偶ytych token贸w
        $total_tokens = $result['usage']['total_tokens'];
    }
    else
    {
        $polecenie = "Przetumacz z polskiego na angielski";
    }
?>

<!-- Formularz HTML -->
<form action="" method="POST" name="form">
    Polecenie (kontekst zadania):<br>
    <input name="polecenie" style="width: 100%;" value="<?php echo $polecenie; ?>"><br><br>
    <!-- Pole tekstowe do wpisania fragmentu do przetumaczenia -->
    Fragment do przetumaczenia:<br>
    <textarea name="fragment" style="width: 100%; height: 35%;"><?php echo $fragment; ?></textarea>
    <br>
    <button type="submit">Tumacz</button>
</form>

<?php
    // Je偶eli istnieje tumaczenie
    if(!empty($translated))
    {
?>

        <!-- Wywietla przetumaczony fragment w polu tekstowym z wyczon moliwoci edycji -->
        Przetumaczony tekst:
        <textarea style="width: 100%; height: 35%;" disabled><?php echo $translated; ?></textarea>
        <br><br>

<?php
        // Oblicza koszt wykonania zadania
        $cost = 0.002 * $total_tokens / 1000;
        // Wywietla ilo u偶ytych token贸w
        echo "Tokeny zapytania: ".$prompt_tokens." | Tokeny odpowiedzi: ".$completion_tokens." | Tokeny og贸em: ".$total_tokens."<br>";
        // Wywietla koszt wykonania zadania
        echo "Koszt (przy zao偶eniu cennika dla modelu gpt-3.5-turbo = $0.002 / 1k token贸w): $".$cost;
        echo "<br><br><hr>";
        // Wywietla odpowied藕 od serwera API przekonwertowan na tablic
        echo "Odpowied藕 serwera API:";
        echo "<pre>";
        print_r($result);
        echo "</pre>";
    }
?>
```

W caym tym kodzie najwa偶niejsze s trzy parametry zapytania _cURL_:

- _**CURLOPT\_URL**_ - adres na jaki kierowane jest zapytanie do _API_,

- **CURLOPT\_HTTPHEADER** - znane nam nag贸wki, w kt贸rych zawarty jest _token_ u偶ywany do uwierzytelnienia si i uzyskania dostpu do _API_,

- **CURLOPT\_POSTFIELDS** - samo misko, esencja, najwa偶niejsza cz, czyli informacje jakie wysyamy do _API_.

Chciabym pochyli si jedynie nad tym ostatnim parametrem. Przesyany jest on w postaci obiektu _JSON_, o restrykcyjnie okrelonej strukturze. U偶yem sowa restrykcyjnie, bo wystarczy pomyli jeden znak i cae zapytanie si wysypie. W skrypcie obraem tak taktyk, 偶e najpierw tworz tablic, wypeniam j danymi i dopiero na koniec konwertuj na obiekt _JSON_. W ka偶dym razie, w tej czci zapytania _cURL_ mo偶na okreli takie rzeczy jak:

- _**model**_ - jaki model jzykowy ma zosta u偶yty (lista wszystkich aktualnie dostpnych modeli znajduje si [tutaj](https://platform.openai.com/docs/models/overview)), w momencie pisania tego wpisu najnowszym modelem dostpnym bez subskrypcji jest _gpt-3.5-turbo_, natomiast przy jej wykupieniu (za $20 miesicznie) otrzymujemy dostp do modelu _gpt-4_,

- **_message_** - podzielone na:
    - **_role_** - mamy tutaj dostpne nastpujce role:
        - _system_ - wiadomoci podpisane tak rol to bardzo istotne narzdzie dla u偶ytkownika, kt贸re jest dostpne jedynie z poziomu API (u偶ywajc ChatGPT nie ma mo偶liwoci skorzystania z takiej funkcji), su偶y do okrelenia kontekstu, czyli np. mo偶emy tutaj napisa do _AI_ w jakiej roli ma wystpi - "jeste poet i masz odpisywa wierszem trzynastozgoskowym", lub te偶 po prostu tak jak ja w powy偶szym kodzie wykorzysta t funkcj do okrelenia konkretnego zadania, kt贸re ma zosta wykonane przez _AI_ - "Przetumacz z jzyka polskiego na angielski",
        
        - _user_ - rola, kt贸ra okrela, 偶e dana wiadomo pochodzi od u偶ytkownika (od nas),
        
        - _assistant_ - tak oznaczane s wiadomoci napisane przez _AI_,
    
    - **_content_** - tre wiadomoci,

- **_temperature_** - temperatur okrela si parametr, kt贸ry definiuje jakiego poziomu kreatywnoci, a mo偶e raczej w tym przypadku losowoci, bo ci偶ko powiedzie, 偶e model jzykowy mo偶e by kreatywny, oczekujemy od _AI_ w odpowiedzi na zapytanie, im warto bli偶sza 0 tym odpowied藕 bdzie rzeczowa (dobre, gdy oczekujemy realnej odpowiedzi np. na jakie pytanie lub zadajemy mu po prostu konkretne zadanie do wykonania), natomiast im bli偶ej 1 tym model zacznie po prostu bardziej zmyla (dobre, gdy zadanie ma charakter kreatywny, czyli model ma np. wymyli slogan reklamowy),

- **_max\_tokens_** - maksymalna dugo odpowiedzi liczona w tokenach, kt贸re niestety s ci偶ko przeliczalne na sowa czy chocia偶by litery, w praktyce im mniejszy parametr _max\_tokens_ tym bardziej zwiza bdzie odpowied藕.

Jak wida u偶ywajc tej metody, czyli komunikacji poprzez _API_, co prawda pacimy, ale mamy mo偶liwo skonfigurowania znaczniej wikszej liczby parametr贸w ni偶 przy zwykej rozmowie z _ChatGPT_. Te parametry pozwalaj nam w znacznym stopniu okreli swoje potrzeby i zoptymalizowa proces, kt贸ry tworzymy w oparciu o wykorzystanie _GPT_. Wedug mnie szczeg贸lnie istotne jest pobawienie si parametrem _temperature_, kt贸ry powinien by dostosowany odpowiednio do danego zastosowania. Niemniej istotne jest okrelenie odpowiedniego kontekstu poprzez wysanie wiadomoci z rol system, kt贸ra nakreli _GPT_ jak ma podej do danego zadania. Sformuowanie odpowiedniej wiadomoci to wedug mnie dopiero trzeci wa偶ny aspekt caego procesu. Ludzie mieszkuj, 偶e teraz powstan nowe stanowiska pracy nazywajce si _Prompt Engineer/Specialist_. Zastan贸w si jednak, czy po przeczytaniu wszystkiego co napisaem powy偶ej, te偶 uwa偶asz, 偶e taka specjalizacja nie miaaby sensu? Je偶eli tak to proponuj spr贸bowa wasnych si z wyciniciem z _GPT_, w spos贸b optymalny, dokadnie takiej odpowiedzi jakiej oczekujesz, powodzenia! 

## Sprawd藕my dziaanie skryptu

Wynik dziaania powy偶szego skryptu, po wrzuceniu do niego treci wstpu tego wpisu, prezentuje si nastpujco:

![](/images/gptapi2.png)

Jak wida jako tumaczenia jest na cakiem niezym poziomie. Oczywicie potrzebna jest pewna korekta, ale te偶 trzeba przyzna, 偶e m贸j styl wyra偶ania swoich myli nie jest do koca atwy w analizie, a w szczeg贸lnoci je偶eli trzeba go przeo偶y na inny jzyk. Przy wykonaniu tego zadania u偶ylimy w sumie 869 _token贸w_, co przekada si na koszt w wysokoci uamk贸w jednego centa (niecae 0.2 centa, czyli w praktyce za 1 centa mo偶na wykona a偶 pi podobnych zada, a za jednego dolara mo偶na ich zrobi 500). Teraz rozumiesz ile mo偶na zrobi za 5 dolar贸w, o kt贸rych m贸wiem wczeniej?

## Odpowied藕 od serwera API

Na koniec zwr贸my jeszcze uwag jak wyglda odpowied藕 od serwera API:

```markup
Array
(
    [id] => chatcmpl-74ECqgzzmsDLEH62Te6QXFxO72nqY
    [object] => chat.completion
    [created] => 1681242276
    [model] => gpt-3.5-turbo-0301
    [usage] => Array
        (
            [prompt_tokens] => 544
            [completion_tokens] => 325
            [total_tokens] => 869
        )

    [choices] => Array
        (
            [0] => Array
                (
                    [message] => Array
                        (
                            [role] => assistant
                            [content] => ChatGPT is currently on everyone's lips. It's almost coming out of our refrigerators. We hear discussions about it on the internet, TV, and radio all the time, such as whether it is the future, how many jobs it will take away, and how innovative the solution is. Well, I won't dwell on it too much here because, like you, dear reader, I'm a bit tired of all this talk for nothing. I'll just say briefly that AI is undoubtedly the future, whether we like it or not. Maybe not in its current form, but it will evolve and develop very quickly. The only thing we can do now is to get on the fastest horse we have in the corral, ride ahead, catch up with that train, and try to get on it while we still can. For me, GPT and other models like it are innovations of modern times that can already be compared to the breakthrough of smartphones, and this is just the beginning of the road. We are facing a challenge now - are you getting on board or falling behind? I can't say that I'm already on the train called the AI Expert Express because I feel like I've only just scratched the surface, but I'm on a horse, and if you want, I can take you on the back seat, and together we'll try to catch that train. That's exactly what this post is about. Leaving behind the metaphorical talk - in this post, I'll show you how to communicate with artificial intelligence created by OpenAI, specifically how to use the GPT model through their API.
                        )

                    [finish_reason] => stop
                    [index] => 0
                )

        )

)
```

Jak wida w odpowiedzi zawarte s m.in. informacje:

- jakie jest ID danej konwersacji, ciekawe czy na podstawie tego ID mo偶na p贸藕niej do niej jako nawiza... tego jeszcze nie testowaem,

- jaki model zosta u偶yty,

- ile token贸w zostao u偶ytych, z podziaem na prompt, odpowied藕 i sum,

- odpowied藕 docelow,

- z jakim statusem zostao zakoczone generowanie odpowiedzi, gdzie _stop_ oznacza, 偶e model zakoczy zadanie prawidowo i sam si zatrzyma, a np. _length_ oznacza, 偶e ustawiono zbyt ma warto w parametrze _max\_tokens_ i modelowi po prostu nie wystarczyo znak贸w, aby prawidowo zakoczy odpowied藕 (przewa偶nie jest wtedy po prostu urwana w miejscu, w kt贸rym wyczerpay si dostpne tokeny).
